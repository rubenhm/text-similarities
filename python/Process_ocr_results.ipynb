{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import io\n",
    "import tempfile\n",
    "import json\n",
    "import sys\n",
    "from pprint import pprint\n",
    "from google.cloud import storage\n",
    "from google.cloud import vision\n",
    "from google.cloud import texttospeech\n",
    "from google.cloud import automl_v1beta1 as automl\n",
    "from google.protobuf import json_format\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jenkspy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to extract information from JSON file\n",
    "# https://github.com/kazunori279/pdf2audiobook/blob/master/functions/app/main.py\n",
    "# https://stackoverflow.com/questions/51972479/get-lines-and-paragraphs-not-symbols-from-google-vision-api-ocr-on-pdf\n",
    "def extract_paragraph_feature(para_id, para):\n",
    "\n",
    "    # collect text\n",
    "    text = \"\"\n",
    "    \n",
    "    # Initialize list of character height of words in paragraph\n",
    "    wcheight_list = [] \n",
    "    breaks = vision.enums.TextAnnotation.DetectedBreak.BreakType\n",
    "    for word in para.words:\n",
    "        # Get bounding box coordinates to calculate height word\n",
    "        cy_list = []\n",
    "        for v in word.bounding_box.normalized_vertices:\n",
    "            cy_list.append(v.y)\n",
    "        # Calculate height of character\n",
    "        wcheight_list.append(max(cy_list) - min(cy_list))\n",
    "        for symbol in word.symbols:\n",
    "            # Append characters to form text\n",
    "            text += symbol.text\n",
    "            # Add spaces or linebreaks to text string\n",
    "            if hasattr(symbol.property, \"detected_break\"):\n",
    "                break_type = symbol.property.detected_break.type\n",
    "                if break_type == breaks.SPACE:\n",
    "                    text += \" \"  # if the break is SPACE\n",
    "                if break_type == breaks.EOL_SURE_SPACE:\n",
    "                    text += \" \"  # this is not a line break, why is there detected_break\n",
    "                if break_type == breaks.LINE_BREAK:\n",
    "                    text += \"\\r\\n\" # if the break is a LINE_BREAK\n",
    "                    \n",
    "   #print(np.unique(breaks))\n",
    "    \n",
    "    # Average height of words in paragraph\n",
    "    pcheight = np.average(wcheight_list)\n",
    "    \n",
    "    # remove double quotes\n",
    "    text = text.replace('\"', \"\")\n",
    "\n",
    "    # remove URLs\n",
    "    text = re.sub(\"https?://[\\w/:%#\\$&\\?\\(\\)~\\.=\\+\\-]+\", \"\", text)\n",
    "\n",
    "    # extract bounding box features of the paragraph\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    for v in para.bounding_box.normalized_vertices:\n",
    "        x_list.append(v.x)\n",
    "        y_list.append(v.y)\n",
    "    f = {}\n",
    "    f[\"para_id\"] = para_id\n",
    "    f[\"page\"] = para_id[8:11]\n",
    "    f[\"text\"] = text\n",
    "    f[\"avg_word_height\"] = pcheight*1000\n",
    "    f[\"width\"] = max(x_list) - min(x_list)\n",
    "    f[\"height\"] = max(y_list) - min(y_list)\n",
    "    f[\"area\"] = f[\"width\"] * f[\"height\"]\n",
    "    f[\"chars\"] = len(text)\n",
    "    f[\"char_size\"] = f[\"area\"] / f[\"chars\"] if f[\"chars\"] > 0 else 0\n",
    "    f[\"pos_x\"] = (f[\"width\"] / 2.0) + min(x_list)\n",
    "    f[\"pos_y\"] = (f[\"height\"] / 2.0) + min(y_list)\n",
    "    f[\"aspect\"] = f[\"width\"] / f[\"height\"] if f[\"height\"] > 0 else 0\n",
    "    f[\"layout\"] = \"h\" if f[\"aspect\"] > 1 else \"v\"\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to form csv file from json response\n",
    "def build_feature_csv(json_blob, pdf_id, first_page):\n",
    "\n",
    "    # parse json\n",
    "    json_string = json_blob\n",
    "    json_response = json_format.Parse(json_string, vision.types.AnnotateFileResponse())\n",
    "\n",
    "    # covert the json file to a bag of CSV lines\n",
    "    csv = \"\"\n",
    "    page_count = first_page\n",
    "    for resp in json_response.responses:\n",
    "        para_count = 0\n",
    "        for page in resp.full_text_annotation.pages:\n",
    "\n",
    "            # collect para features for the page\n",
    "            page_features = []\n",
    "            for block in page.blocks:\n",
    "                if str(block.block_type) != \"1\":  # process only TEXT blocks\n",
    "                    continue\n",
    "                for para in block.paragraphs:\n",
    "                    para_id = \"{}-{:03}-{:03}\".format(pdf_id, page_count, para_count)\n",
    "                    f = extract_paragraph_feature(para_id, para)\n",
    "                    page_features.append(f)\n",
    "                    para_count += 1\n",
    "\n",
    "            # output to csv\n",
    "            for f in page_features:\n",
    "                csv += '{},{},\"{}\",{},{:.6f},{:.6f},{:.6f},{:.6f},{:.6f},{:.6f},{:.6f},{:.6f},{}\\n'.format(\n",
    "                    f[\"para_id\"],\n",
    "                    f[\"page\"],\n",
    "                    f[\"text\"],\n",
    "                    f[\"chars\"],\n",
    "                    f[\"avg_word_height\"],\n",
    "                    f[\"width\"],\n",
    "                    f[\"height\"],\n",
    "                    f[\"area\"],\n",
    "                    f[\"char_size\"],\n",
    "                    f[\"pos_x\"],\n",
    "                    f[\"pos_y\"],\n",
    "                    f[\"aspect\"],\n",
    "                    f[\"layout\"],\n",
    "                )\n",
    "\n",
    "        page_count += 1\n",
    "    return csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to process all files and save csv to file\n",
    "def process_ocr_text(filename):\n",
    "    \n",
    "    # Get pdf id and first page number from file name\n",
    "    m = re.match(\"out_([0-9]+)output-([0-9]+)-to-([0-9]+)\\.json\", filename)\n",
    "    pdf_id = m.group(1)\n",
    "    first_page = int(m.group(2))\n",
    "    last_page  = int(m.group(3))\n",
    "    \n",
    "    # Read json source \n",
    "    data = json.loads(open('data/data-gen/' + filename).read())\n",
    "    \n",
    "    # Convert json to string\n",
    "    json_blob = json.dumps(data)\n",
    "    \n",
    "    # Convert to csv string\n",
    "    csv_out = build_feature_csv(json_blob, pdf_id, first_page)\n",
    "    \n",
    "    return csv_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read list of files to process\n",
    "mypath = 'data/data-gen/json'\n",
    "f = []\n",
    "for (dirpath, dirnames, filenames) in os.walk(mypath):\n",
    "    f.extend(filenames)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all json files\n",
    "csv_txt = \"\"\n",
    "\n",
    "# Concatenate all files into a single string\n",
    "for fname in f:\n",
    "    # Process file fname\n",
    "    csv_out = process_ocr_text(fname)\n",
    "    # Concatenate strings\n",
    "    csv_txt += csv_out\n",
    "    \n",
    "# Convert to pandas df\n",
    "colnames = ['id','page','text','chars','avg_word_height','width','height','area','char_size','pos_x','pos_y','aspect','layout']\n",
    "big_df = pd.read_csv(io.StringIO(csv_txt), names=colnames)\n",
    "\n",
    "# Save big data frame as pickle\n",
    "big_df.to_pickle('data/data-gen/big_df.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43790, 13)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_fomc",
   "language": "python",
   "name": "py37_fomc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
